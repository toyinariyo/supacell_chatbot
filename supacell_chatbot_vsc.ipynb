{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import os\n",
    "import json \n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import time \n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "#import ipywidgets as widgets\n",
    "#from IPython.display import display, clear_output\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]\n",
      "Current working directory: c:\\GitHub\\peckham_daz_natural_language_processing\\supacell_chatbot\n",
      "Using NLTK data directory: c:\\GitHub\\peckham_daz_natural_language_processing\\supacell_chatbot\\nltk_data\n",
      "\n",
      "Downloading tokenizers/punkt...\n",
      "Download result: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading tokenizers/punkt: Package 'tokenizers/punkt'\n",
      "[nltk_data]     not found in index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Verified tokenizers/punkt exists at c:\\GitHub\\peckham_daz_natural_language_processing\\supacell_chatbot\\nltk_data\\tokenizers\\punkt\n",
      "\n",
      "Downloading corpora/stopwords...\n",
      "Download result: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading corpora/stopwords: Package\n",
      "[nltk_data]     'corpora/stopwords' not found in index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Verified corpora/stopwords exists at c:\\GitHub\\peckham_daz_natural_language_processing\\supacell_chatbot\\nltk_data\\corpora\\stopwords\n",
      "✓ Punkt tokenizer working! Found 2 sentences.\n",
      "✓ Stopwords working! Found 198 stopwords.\n",
      "\n",
      "Final NLTK data path:\n",
      "- c:\\GitHub\\peckham_daz_natural_language_processing\\supacell_chatbot\\nltk_data\n",
      "- C:\\Users\\toyin/nltk_data\n",
      "- c:\\GitHub\\peckham_daz_natural_language_processing\\supacell_chatbot\\venv\\nltk_data\n",
      "- c:\\GitHub\\peckham_daz_natural_language_processing\\supacell_chatbot\\venv\\share\\nltk_data\n",
      "- c:\\GitHub\\peckham_daz_natural_language_processing\\supacell_chatbot\\venv\\lib\\nltk_data\n",
      "- C:\\Users\\toyin\\AppData\\Roaming\\nltk_data\n",
      "- C:\\nltk_data\n",
      "- D:\\nltk_data\n",
      "- E:\\nltk_data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Print Python version and working directory for troubleshooting\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Define the NLTK data directory in the current working directory\n",
    "nltk_data_dir = os.path.join(os.getcwd(), 'nltk_data')\n",
    "os.makedirs(nltk_data_dir, exist_ok=True)\n",
    "print(f\"Using NLTK data directory: {nltk_data_dir}\")\n",
    "\n",
    "# Add our directory to the beginning of NLTK's search path\n",
    "nltk.data.path.insert(0, nltk_data_dir)\n",
    "\n",
    "# Function to download and verify a specific NLTK resource\n",
    "def download_and_verify(package_name):\n",
    "    print(f\"\\nDownloading {package_name}...\")\n",
    "    download_result = nltk.download(package_name, download_dir=nltk_data_dir, quiet=False)\n",
    "    print(f\"Download result: {download_result}\")\n",
    "    \n",
    "    # Give filesystem time to update\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Verify the package exists in our directory\n",
    "    package_path = os.path.join(nltk_data_dir, *package_name.split('/'))\n",
    "    if os.path.exists(package_path) or os.path.exists(package_path + '.zip'):\n",
    "        print(f\"✓ Verified {package_name} exists at {package_path}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"✗ Could not find {package_name} at {package_path}\")\n",
    "        return False\n",
    "\n",
    "# Download both resources\n",
    "punkt_success = download_and_verify(\"tokenizers/punkt\")\n",
    "stopwords_success = download_and_verify(\"corpora/stopwords\")\n",
    "\n",
    "# Now try to use the resources\n",
    "if punkt_success:\n",
    "    try:\n",
    "        from nltk.tokenize import sent_tokenize\n",
    "        sentences = sent_tokenize(\"This is a test. This is another test.\")\n",
    "        print(f\"✓ Punkt tokenizer working! Found {len(sentences)} sentences.\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error using punkt tokenizer: {str(e)}\")\n",
    "\n",
    "if stopwords_success:\n",
    "    try:\n",
    "        from nltk.corpus import stopwords\n",
    "        stop_words = stopwords.words('english')\n",
    "        print(f\"✓ Stopwords working! Found {len(stop_words)} stopwords.\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error using stopwords: {str(e)}\")\n",
    "\n",
    "print(\"\\nFinal NLTK data path:\")\n",
    "for path in nltk.data.path:\n",
    "    print(f\"- {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\toyin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded profiles for 5 characters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def parse_character_profiles(file_path):\n",
    "    \"\"\"Parse character profiles from the text file\"\"\"\n",
    "    characters = {}\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        # Split by character names\n",
    "        character_blocks = re.split(r'(Michael Lasaki-Brown|Tayo \"Tazer\" Amusan|Sabrina Clarke|Andre Simpson|Rodney Cullen)', content)\n",
    "        \n",
    "        # Process each block\n",
    "        current_character = None\n",
    "        for block in character_blocks:\n",
    "            block = block.strip()\n",
    "            if block in [\"Michael Lasaki-Brown\", \"Tayo \\\"Tazer\\\" Amusan\", \"Sabrina Clarke\", \"Andre Simpson\", \"Rodney Cullen\"]:\n",
    "                current_character = block\n",
    "                characters[current_character] = \"\"\n",
    "            elif current_character and block:\n",
    "                characters[current_character] = block\n",
    "        \n",
    "        return characters\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing profiles: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "# Parse profiles\n",
    "profiles_file = \"character_profiles.txt\"\n",
    "if os.path.exists(profiles_file):\n",
    "    character_profiles = parse_character_profiles(profiles_file)\n",
    "    print(f\"Loaded profiles for {len(character_profiles)} characters\")\n",
    "else:\n",
    "    print(f\"Profile file not found: {profiles_file}\")\n",
    "    character_profiles = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed profile for Michael\n",
      "Processed profile for Tayo\n",
      "Processed profile for Rodney\n",
      "Processed profile for Sabrina\n",
      "Processed profile for Andre\n",
      "Available characters: Michael Lasaki-Brown, Tayo \"Tazer\" Amusan, Rodney Cullen, Sabrina Clarke, Andre Simpson\n"
     ]
    }
   ],
   "source": [
    "# Create character info dictionary\n",
    "character_info = {}\n",
    "\n",
    "for character, profile in character_profiles.items():\n",
    "    # Format profile for better prompting\n",
    "    formatted_profile = f\"Character: {character}\\n\\n{profile}\"\n",
    "    \n",
    "    # Simplify character name for display\n",
    "    display_name = character.split()[0]  # Just use first name\n",
    "    \n",
    "    # Store in dictionary\n",
    "    character_info[character] = formatted_profile\n",
    "    \n",
    "    print(f\"Processed profile for {display_name}\")\n",
    "\n",
    "# If no profiles were loaded, use defaults\n",
    "if not character_info:\n",
    "    character_info = {\n",
    "        'Michael Lasaki-Brown': 'Character who can teleport and time travel, trying to save Dionne',\n",
    "        'Tayo \"Tazer\" Amusan': 'Gang leader with invisibility powers',\n",
    "        'Sabrina Clarke': 'Nurse with telekinesis abilities',\n",
    "        'Andre Simpson': 'Father with super strength trying to protect his son',\n",
    "        'Rodney Cullen': 'Drug dealer with super-speed and healing powers'\n",
    "    }\n",
    "\n",
    "# List available characters\n",
    "characters_available = list(character_info.keys())\n",
    "print(f\"Available characters: {', '.join(characters_available)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define character speech patterns for more authentic responses\n",
    "character_speech = {\n",
    "    \"Michael Lasaki-Brown\": {\n",
    "        \"prefixes\": [\"Listen, \", \"I need to tell you, \", \"\"],\n",
    "        \"fillers\": [\", yeah?\", \", I swear\", \"\"],\n",
    "        \"topics\": [\"Dionne\", \"future\", \"teleportation\", \"powers\", \"saving\"]\n",
    "    },\n",
    "    \"Tayo \\\"Tazer\\\" Amusan\": {\n",
    "        \"prefixes\": [\"\", \"Yo, \", \"Look man, \"],\n",
    "        \"fillers\": [\", bruv\", \", fam\", \", man\", \", yeah?\"],\n",
    "        \"topics\": [\"gang\", \"invisibility\", \"Tower Boys\", \"respect\", \"money\"]\n",
    "    },\n",
    "    \"Sabrina Clarke\": {\n",
    "        \"prefixes\": [\"\", \"I \", \"\"],\n",
    "        \"fillers\": [\"\", \", seriously\", \", honestly\"],\n",
    "        \"topics\": [\"telekinesis\", \"Sharleen\", \"nurse\", \"control\", \"patient\"]\n",
    "    },\n",
    "    \"Andre Simpson\": {\n",
    "        \"prefixes\": [\"\", \"Look, \", \"Man, \"],\n",
    "        \"fillers\": [\", man\", \", innit\", \", yeah?\"],\n",
    "        \"topics\": [\"AJ\", \"son\", \"strength\", \"job\", \"money\"]\n",
    "    },\n",
    "    \"Rodney Cullen\": {\n",
    "        \"prefixes\": [\"Mate, \", \"Listen, \", \"\"],\n",
    "        \"fillers\": [\", bruv\", \", yeah?\", \", you get me?\"],\n",
    "        \"topics\": [\"speed\", \"deal\", \"business\", \"run\", \"Spud\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to make responses sound like the character\n",
    "def apply_speech_pattern(character, text):\n",
    "    \"\"\"Apply character's speech pattern to make response more authentic\"\"\"\n",
    "    \n",
    "    if character not in character_speech:\n",
    "        return text\n",
    "    \n",
    "    speech = character_speech[character]\n",
    "    \n",
    "    # 30% chance to add a prefix if text doesn't already have one\n",
    "    if random.random() < 0.3 and not any(text.startswith(p) for p in speech[\"prefixes\"] if p):\n",
    "        prefix = random.choice(speech[\"prefixes\"])\n",
    "        if prefix:\n",
    "            text = prefix + text[0].lower() + text[1:]\n",
    "    \n",
    "    # 40% chance to add a filler\n",
    "    if random.random() < 0.4:\n",
    "        filler = random.choice(speech[\"fillers\"])\n",
    "        if filler:\n",
    "            # Find a sentence break to insert the filler\n",
    "            sentences = text.split(\". \")\n",
    "            if len(sentences) > 1:\n",
    "                pos = random.randint(0, len(sentences)-1)\n",
    "                sentences[pos] = sentences[pos] + filler\n",
    "                text = \". \".join(sentences)\n",
    "            else:\n",
    "                text = text + filler\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dialogue model...\n",
      "Using CPU for inference (this might be slower)\n",
      "Model loaded: google/flan-t5-small\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Loading dialogue model...\")\n",
    "model_name = \"google/flan-t5-small\" # Model that runs fast on CPU and doesn't require me to install CUDA Toolkit \n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Move to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(\"cuda\")\n",
    "    print(\"Model moved to GPU\")\n",
    "else:\n",
    "    print(\"Using CPU for inference (this might be slower)\")\n",
    "\n",
    "print(f\"Model loaded: {model_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get pre-defined responses for common questions\n",
    "def get_templated_response(character, query):\n",
    "    \"\"\"Get pre-defined responses for common questions\"\"\"\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Character powers\n",
    "    if any(word in query_lower for word in [\"power\", \"ability\", \"superpower\", \"what can you do\"]):\n",
    "        power_responses = {\n",
    "            \"Michael Lasaki-Brown\": \"I can teleport - move from one place to another in seconds. I can also manipulate time, but I don't have full control over that yet. It started when I got stabbed by Tazer, and I rewound time without even meaning to. My eyes glow yellow when I use my powers, yeah?\",\n",
    "            \n",
    "            \"Tayo \\\"Tazer\\\" Amusan\": \"I can turn invisible, fam. Nobody can see me when it happens. First time was like a week ago in my room. My eyes started tingling, checked the mirror, there was nobody there. I use it when I need to, yeah? Powers can run out though if I overuse them.\",\n",
    "            \n",
    "            \"Sabrina Clarke\": \"I have telekinesis - I can move objects without touching them. I discovered it when I found out my boyfriend Kevin was cheating. I was so angry that I threw him against a wall without even touching him. I'd rather not have these abilities. I've already killed someone by accident.\",\n",
    "            \n",
    "            \"Andre Simpson\": \"I've got super strength, man. First happened at that ATM when I was desperate for cash. I can bend metal, lift cars, things like that. Still figuring out what my limits are. My eyes go yellow when I use it.\",\n",
    "            \n",
    "            \"Rodney Cullen\": \"I've got super-speed, mate! I accidentally ran all the way to Scotland in like a minute. And I heal fast too. The speed thing gives me proper munchies though, you get me? Always starving after using it.\"\n",
    "        }\n",
    "        return power_responses.get(character, \"\")\n",
    "    \n",
    "    # Origin stories\n",
    "    elif any(word in query_lower for word in [\"discover\", \"first time\", \"how did you get\", \"when did you\", \"find out\"]):\n",
    "        origin_responses = {\n",
    "            \"Michael Lasaki-Brown\": \"It happened when I got stabbed by Tazer. Somehow, I rewound time and avoided it completely. Then I started teleporting without even trying to. I even saw the future - July 9, 2024. That's when... Listen, I need to find the others with powers to prevent something terrible from happening.\",\n",
    "            \n",
    "            \"Tayo \\\"Tazer\\\" Amusan\": \"First time was in my room, bruv. Eyes started tingling, looked in the mirror, and couldn't see myself. It was mad. Then I used it to take care of some Sixers, know what I'm saying? Now I can control it proper.\",\n",
    "            \n",
    "            \"Sabrina Clarke\": \"I discovered it in the worst possible way. I found out Kevin was cheating on me. I was so angry, and suddenly he was thrown against the door without me touching him. I've never called in sick before that day. I just wanted things to go back to normal.\",\n",
    "            \n",
    "            \"Andre Simpson\": \"It happened at the ATM, man. Got fired from my call centre job because of my record. Couldn't get money for my son AJ. I got so frustrated I punched the ATM, and my fist went straight through it. Took all the cash to provide for my boy.\",\n",
    "            \n",
    "            \"Rodney Cullen\": \"Listen, I was late for a drop, yeah? Needed to be quick, and suddenly I'm in Scotland, bruv! Took me like a minute to get there! At first, I couldn't control it, but now I'm using it for business. Five minutes or free delivery, you get me?\"\n",
    "        }\n",
    "        return origin_responses.get(character, \"\")\n",
    "    \n",
    "    # Relationships with other characters\n",
    "    elif any(name.lower() in query_lower for name in [\"michael\", \"tazer\", \"sabrina\", \"andre\", \"rodney\", \"dionne\", \"spud\", \"aj\", \"sharleen\", \"krazy\"]):\n",
    "        # Find which character is mentioned\n",
    "        mentioned_chars = [name for name in [\"michael\", \"tazer\", \"sabrina\", \"andre\", \"rodney\", \"dionne\", \"spud\", \"aj\", \"sharleen\", \"krazy\"] if name.lower() in query_lower]\n",
    "        if mentioned_chars:\n",
    "            mentioned = mentioned_chars[0]\n",
    "            \n",
    "            # Define relationship responses\n",
    "            relationships = {\n",
    "                (\"Michael Lasaki-Brown\", \"tazer\"): \"Tazer stabbed me in a timeline that got erased when my powers first manifested. I remember it, but he doesn't. Now I'm trying to convince him to join me, but he's suspicious and hostile.\",\n",
    "                (\"Michael Lasaki-Brown\", \"sabrina\"): \"I've warned Sabrina about the hooded figures and told her we need to work together, but she's reluctant. She has telekinesis and could fly in the future. She says she can't fly now though.\",\n",
    "                (\"Michael Lasaki-Brown\", \"andre\"): \"I haven't properly met Andre yet. He once held a door open for me, but I don't think he even remembers that. I know he has super strength but that's it.\",\n",
    "                (\"Michael Lasaki-Brown\", \"rodney\"): \"Rodney tried selling me drugs before his powers manifested. Later, I saved him from one of those hooded figures with pyrokinesis. He's dismissive about my warnings though - thinks it's a 'me problem'.\",\n",
    "                (\"Michael Lasaki-Brown\", \"dionne\"): \"Dionne is my fiancée. I love her more than anything. In the future I saw, she dies on July 9, 2024. That's why I'm trying to find everyone with powers - to prevent that from happening. I haven't told her about it.\",\n",
    "                \n",
    "                (\"Tayo \\\"Tazer\\\" Amusan\", \"michael\"): \"That delivery guy? He came to me talking about powers and shit. Don't know how he knew I have powers. Saw him teleport in front of me. Had me shook for a bit. He's on about some hooded figures coming after us. Don't trust him, to be honest.\",\n",
    "                (\"Tayo \\\"Tazer\\\" Amusan\", \"krazy\"): \"Krazy? He used to run the Tower Boys before me. I looked up to him, fam. But then he came back and shot Tiny - one of my brothers. The doctor said Tiny might not walk again. Krazy's not my brother no more. Next time I see him, I'm gonna kill him.\",\n",
    "                (\"Sabrina Clarke\", \"michael\"): \"Michael approached me claiming he has powers too. I didn't believe him until I saw his eyes glow yellow like mine. I saw him teleport out of my car, it was mad. He warned me about some hooded figures hunting people with abilities. I'm skeptical, but after what happened with Kadeem, I don't know what to believe anymore.\",\n",
    "                (\"Sabrina Clarke\", \"sharleen\"): \"Sharleen is my sister. I'm very protective of her - especially after what happened with Kadeem. I wish she'd stay away from guys like Krazy. She deserves better. I'd do anything to keep her safe.\",\n",
    "                (\"Andre Simpson\", \"michael\"): \"Don't really know him. Think I held a door for him once. Got my own problems to deal with, trying to provide for AJ and stay out of trouble. \",\n",
    "                (\"Andre Simpson\", \"aj\"): \"AJ is my son, man. The most important person in my life. I was in prison for a while, so I'm trying to make up for lost time. His mother Aisha's with a guy named Dwayne now. I'm determined to keep AJ away from gang life.\",\n",
    "                (\"Rodney Cullen\", \"michael\"): \"That guy? Tried to sell him some product before all this power madness. Then he comes saving me from some fire-throwing nutter in a hood. Now he's on about needing my help with some mission. Sounds like a 'him' problem, you get me?\",\n",
    "                (\"Rodney Cullen\", \"spud\"): \"Spud's my best mate and business partner. We run the drug game together. He's the one who doubted my superspeed at first but now he's treating me like I'm the fucking Flash. It's proper annoying but I can't blame him. I mean, I did run to Scotland in a minute. He's a muppet but I love him.\"\n",
    "            }\n",
    "            \n",
    "            return relationships.get((character, mentioned), \"\")\n",
    "        \n",
    "    elif any(word in query_lower for word in [\"yellow eyes\", \"eyes glow\", \"eyes turn\"]):\n",
    "            # Define eye color responses\n",
    "        eye_color_responses = {\n",
    "            \"Michael Lasaki-Brown\": \"My eyes glow yellow when I use my powers. It's a sign that I'm teleporting or manipulating time. It happens to all of us with powers.\",\n",
    "            \"Tayo \\\"Tazer\\\" Amusan\": \"My eyes go yellow when I turn invisible, fam. First time it happened, they were just tingling. Next thing I know, I can't see myself in the mirror. It's a bit mad, innit?\",\n",
    "            \"Sabrina Clarke\": \"My eyes glow yellow when I use my telekinesis. It's a bit scary, to be honest. I think it happens to everyone with powers. Kadeem and Michael's eyes glow yellow and they have powers. Those guys at Krazy's warehouse had yellow eyes too.\",\n",
    "            \"Andre Simpson\": \"My eyes go yellow when I use my strength. Don't really understand why, but it happens every time.\",\n",
    "            \"Rodney Cullen\": \"My eyes go proper yellow when I'm using my speed, bruv! Like a warning light or something, innit? Happens to all of us with these freaky powers as far as I can tell.\"\n",
    "        }\n",
    "        \n",
    "        return eye_color_responses.get(character, \"\")\n",
    "        \n",
    "    elif any(phrase in query_lower for phrase in [\"hooded\", \"figures\", \"fire\", \"pyrokinesis\"]):\n",
    "            # Define hooded figures responses\n",
    "        hooded_responses = {\n",
    "            \"Michael Lasaki-Brown\": \"They're dangerous. I first saw them when I went to the future and now they're in the present. They have powers too - saw one that can create fire, another one can make portals. I need to find the others before it's too late.\",\n",
    "            \"Tayo \\\"Tazer\\\" Amusan\": \"Some weird guys in hoods? Haven't seen them myself, fam. That Michael guy was going on about them coming after people with powers. Don't know if I believe that.\",\n",
    "            \"Sabrina Clarke\": \"Michael mentioned something about hooded figures hunting people with powers. I haven't seen them personally and I'm not sure I believe everything he says. But after what happened with Kadeem, I don't know what to think.\",\n",
    "            \"Andre Simpson\": \"Hooded figures? What are you talking about, man? I've got enough real problems without worrying about some made-up threat.\",\n",
    "            \"Rodney Cullen\": \"Yeah, I saw one of those nutters! Had some fire powers or something. Would've been burnt to a crisp if Michael hadn't shown up, to be fair. Still not getting involved in all that. Got a business to run, you get me?\"\n",
    "        }\n",
    "        \n",
    "        return hooded_responses.get(character, \"\")\n",
    "\n",
    "    \n",
    "    return \"\"  # No template matched\n",
    "\n",
    "# Modify response generation function to use templates\n",
    "def generate_response(character, query, history=\"\"):\n",
    "    \"\"\"Generate an in-character response with templates for common questions\"\"\"\n",
    "    \n",
    "    # Check for templated responses first\n",
    "    templated_response = get_templated_response(character, query)\n",
    "    if templated_response:\n",
    "        # Apply speech pattern to ensure it sounds authentic\n",
    "        return apply_speech_pattern(character, templated_response)\n",
    "    \n",
    "    # If no template matches the user's query, use the model to generate a response\n",
    "    try:\n",
    "       \n",
    "        info = character_info.get(character, \"\")\n",
    "        prompt = f\"\"\" \n",
    "Generate a response as {character} from Supacell.\n",
    "\n",
    "Character Information:\n",
    "{info[:500]}\n",
    "\n",
    "Previous conversation:\n",
    "{history[-200:] if history else \"\"}\n",
    "\n",
    "User: {query}\n",
    "\n",
    "{character} should respond:\"\"\"\n",
    "        \n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs, \n",
    "                max_length=150, \n",
    "                num_return_sequences=1, \n",
    "                do_sample=True, \n",
    "                top_p=0.9, \n",
    "                temperature=0.7\n",
    "                )\n",
    "            \n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        # Apply character's speech pattern to their response\n",
    "        response = apply_speech_pattern(character, response)\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return \"Sorry, I'm having trouble responding right now.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toyin\\AppData\\Local\\Temp\\ipykernel_344\\3528639891.py:30: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(height=500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7872\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Gradio interface\n",
    "\n",
    "def respond(message, history, character):\n",
    "    \"\"\"Handle chatbot response generation\"\"\"\n",
    "    if not message.strip():\n",
    "        return \"\", history\n",
    "    \n",
    "    # Build conversation history text\n",
    "    history_text = \"\"\n",
    "    for human, ai in history:\n",
    "        history_text += f\"User: {human}\\n{character}: {ai}\\n\"\n",
    "    \n",
    "    # Generate response\n",
    "    response = generate_response(character, message, history_text)\n",
    "    \n",
    "    # Update history\n",
    "    history.append((message, response))\n",
    "    return \"\", history\n",
    "\n",
    "# Create Gradio interface to interact with Supacell characters\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Supacell Character Chatbot\")\n",
    "    \n",
    "    character_dropdown = gr.Dropdown(\n",
    "        choices=characters_available,\n",
    "        label=\"Select Character\",\n",
    "        value=characters_available[0] if characters_available else None\n",
    "    )\n",
    "    \n",
    "    chatbot = gr.Chatbot(height=500)\n",
    "    message = gr.Textbox(placeholder=\"Type your message here...\")\n",
    "    send = gr.Button(\"Send\")\n",
    "    clear = gr.Button(\"Clear\")\n",
    "    \n",
    "    # Set up interactions\n",
    "    send.click(respond, [message, chatbot, character_dropdown], [message, chatbot])\n",
    "    message.submit(respond, [message, chatbot, character_dropdown], [message, chatbot])\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "    \n",
    "    # Add example questions\n",
    "    gr.Examples(\n",
    "        examples=[\n",
    "            [\"What's your power?\"],\n",
    "            [\"How did you discover your abilities?\"],\n",
    "            [\"What's your biggest fear?\"],\n",
    "            [\"Tell me about the other characters\"]\n",
    "        ],\n",
    "        inputs=message\n",
    "    )\n",
    "\n",
    "# Launch the interface\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
